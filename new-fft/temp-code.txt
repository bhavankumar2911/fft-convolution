#pragma once
#ifndef FFT_CROSS_CORRELATION_2D_CUDA_HPP
#define FFT_CROSS_CORRELATION_2D_CUDA_HPP

#include "Matrix2D.hpp"
#include "PaddingMode.hpp"

#include <cuda_runtime.h>
#include <cufft.h>

#include <vector>
#include <unordered_map>
#include <stdexcept>
#include <mutex>

/* ============================================================
   CUDA kernel
   ============================================================ */

static __global__ void multiplyWithConjugate(
    cufftDoubleComplex* imageFreq,
    const cufftDoubleComplex* kernelFreq,
    std::size_t totalSize
)
{
    std::size_t idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < totalSize)
    {
        cufftDoubleComplex a = imageFreq[idx];
        cufftDoubleComplex b = kernelFreq[idx];

        imageFreq[idx].x = a.x * b.x + a.y * b.y;
        imageFreq[idx].y = a.y * b.x - a.x * b.y;
    }
}

/* ============================================================
   FFT plan + buffer cache
   ============================================================ */

struct FFTResources
{
    cufftHandle plan;
    cufftDoubleComplex* d_image;
    cufftDoubleComplex* d_kernel;
    std::size_t totalSize;
};

static std::unordered_map<std::uint64_t, FFTResources> fftCache;
static std::mutex fftCacheMutex;

static std::uint64_t makeKey(std::size_t h, std::size_t w)
{
    return (static_cast<std::uint64_t>(h) << 32) | w;
}

/* ============================================================
   FFT Cross-Correlation (CUDA, optimized)
   ============================================================ */

class FFTCrossCorrelation2D_CUDA
{
public:
    static Matrix2D<double> compute(
        const Matrix2D<double>& image,
        const Matrix2D<double>& kernel,
        PaddingMode paddingMode
    )
    {
        /* ---------------- padding ---------------- */

        std::size_t pad = 0;
        if (paddingMode == PaddingMode::SAME)  pad = kernel.rows() / 2;
        if (paddingMode == PaddingMode::FULL)  pad = kernel.rows() - 1;

        std::size_t paddedH = image.rows() + 2 * pad;
        std::size_t paddedW = image.cols() + 2 * pad;

        std::size_t fftH = 1, fftW = 1;
        while (fftH < paddedH + kernel.rows() - 1) fftH <<= 1;
        while (fftW < paddedW + kernel.cols() - 1) fftW <<= 1;

        std::size_t totalSize = fftH * fftW;
        std::size_t bytes = totalSize * sizeof(cufftDoubleComplex);

        /* ---------------- get cached FFT resources ---------------- */

        std::uint64_t key = makeKey(fftH, fftW);

        FFTResources* res = nullptr;

        {
            std::lock_guard<std::mutex> lock(fftCacheMutex);

            auto it = fftCache.find(key);
            if (it == fftCache.end())
            {
                FFTResources newRes;
                newRes.totalSize = totalSize;

                cudaMalloc(&newRes.d_image, bytes);
                cudaMalloc(&newRes.d_kernel, bytes);

                cufftPlan2d(&newRes.plan, fftH, fftW, CUFFT_Z2Z);

                it = fftCache.emplace(key, newRes).first;
            }
            res = &it->second;
        }

        /* ---------------- host buffers ---------------- */

        std::vector<cufftDoubleComplex> h_image(totalSize, {0.0, 0.0});
        std::vector<cufftDoubleComplex> h_kernel(totalSize, {0.0, 0.0});

        for (std::size_t y = 0; y < image.rows(); ++y)
            for (std::size_t x = 0; x < image.cols(); ++x)
                h_image[(y + pad) * fftW + (x + pad)].x = image(y, x);

        std::size_t kCenterY = kernel.rows() / 2;
        std::size_t kCenterX = kernel.cols() / 2;

        for (std::size_t y = 0; y < kernel.rows(); ++y)
            for (std::size_t x = 0; x < kernel.cols(); ++x)
            {
                std::size_t sy = (y + fftH - kCenterY) % fftH;
                std::size_t sx = (x + fftW - kCenterX) % fftW;
                h_kernel[sy * fftW + sx].x = kernel(y, x);
            }

        /* ---------------- FFT pipeline ---------------- */

        cudaMemcpy(res->d_image, h_image.data(), bytes, cudaMemcpyHostToDevice);
        cudaMemcpy(res->d_kernel, h_kernel.data(), bytes, cudaMemcpyHostToDevice);

        cufftExecZ2Z(res->plan, res->d_image, res->d_image, CUFFT_FORWARD);
        cufftExecZ2Z(res->plan, res->d_kernel, res->d_kernel, CUFFT_FORWARD);

        std::size_t threads = 256;
        std::size_t blocks = (totalSize + threads - 1) / threads;

        multiplyWithConjugate<<<blocks, threads>>>(
            res->d_image, res->d_kernel, totalSize
        );

        cufftExecZ2Z(res->plan, res->d_image, res->d_image, CUFFT_INVERSE);

        cudaMemcpy(h_image.data(), res->d_image, bytes, cudaMemcpyDeviceToHost);

        /* ---------------- crop output ---------------- */

        std::size_t outH, outW, startY, startX;

        if (paddingMode == PaddingMode::SAME)
        {
            outH = image.rows();
            outW = image.cols();
            startY = pad;
            startX = pad;
        }
        else if (paddingMode == PaddingMode::VALID)
        {
            outH = image.rows() - kernel.rows() + 1;
            outW = image.cols() - kernel.cols() + 1;
            startY = kernel.rows() - 1;
            startX = kernel.cols() - 1;
        }
        else
        {
            outH = image.rows() + kernel.rows() - 1;
            outW = image.cols() + kernel.cols() - 1;
            startY = 0;
            startX = 0;
        }

        Matrix2D<double> output(outH, outW);
        double scale = static_cast<double>(fftH * fftW);

        for (std::size_t y = 0; y < outH; ++y)
            for (std::size_t x = 0; x < outW; ++x)
                output(y, x) =
                    h_image[(y + startY) * fftW + (x + startX)].x / scale;

        return output;
    }
};

#endif

#ifndef MATRIX2D_HPP
#define MATRIX2D_HPP

#include <vector>
#include <string>
#include <fstream>
#include <stdexcept>
#include <type_traits>

template<typename T>
class Matrix2D
{
    static_assert(std::is_floating_point<T>::value,
                  "Matrix2D requires float or double");

private:
    std::size_t height;
    std::size_t width;
    std::vector<T> buffer;

public:
    /* -------- REQUIRED DEFAULT CONSTRUCTOR -------- */
    Matrix2D()
        : height(0), width(0), buffer() {}

    /* -------- EXISTING CONSTRUCTOR -------- */
    Matrix2D(std::size_t rows, std::size_t cols)
        : height(rows), width(cols), buffer(rows * cols) {}

    std::size_t rows() const { return height; }
    std::size_t cols() const { return width; }

    T& operator()(std::size_t y, std::size_t x)
    {
        return buffer[y * width + x];
    }

    const T& operator()(std::size_t y, std::size_t x) const
    {
        return buffer[y * width + x];
    }

    T* data()
    {
        return buffer.data();
    }

    const T* data() const
    {
        return buffer.data();
    }

    void readFromBinaryFile(const std::string& path)
    {
        std::ifstream file(path, std::ios::binary);
        if (!file)
            throw std::runtime_error(
                "Failed to open file for reading: " + path
            );

        file.read(reinterpret_cast<char*>(buffer.data()),
                  buffer.size() * sizeof(T));

        if (!file)
            throw std::runtime_error(
                "Binary read failed: " + path
            );
    }

    void writeToBinaryFile(const std::string& path) const
    {
        std::ofstream file(path, std::ios::binary);
        if (!file)
            throw std::runtime_error(
                "Failed to open file for writing: " + path
            );

        file.write(reinterpret_cast<const char*>(buffer.data()),
                   buffer.size() * sizeof(T));

        if (!file)
            throw std::runtime_error(
                "Binary write failed: " + path
            );
    }
};

#endif

#pragma once

enum class PaddingMode
{
    SAME,
    VALID,
    FULL
};

#pragma once
#include "../Matrix2D.hpp"
#include "../FFTCrossCorrelation2D_CUDA.hpp"
#include "../PaddingMode.hpp"
#include <vector>

class Conv2D_FFT
{
    std::size_t inC, outC, k;
    std::vector<Matrix2D<double>> kernels;
    std::vector<double> bias;

public:
    Conv2D_FFT(
        std::size_t iC, std::size_t oC, std::size_t k_,
        const std::vector<double>& w,
        const std::vector<double>& b
    ) : inC(iC), outC(oC), k(k_), bias(b)
    {
        std::size_t off = 0;
        for (std::size_t oc = 0; oc < outC; ++oc)
            for (std::size_t ic = 0; ic < inC; ++ic)
            {
                Matrix2D<double> m(k, k);
                for (std::size_t y = 0; y < k; ++y)
                    for (std::size_t x = 0; x < k; ++x)
                        m(y, x) = w[off++];
                kernels.push_back(std::move(m));
            }
    }

    std::vector<Matrix2D<double>> forward(
        const std::vector<Matrix2D<double>>& in
    ) const
    {
        std::vector<Matrix2D<double>> out(outC);

        for (std::size_t oc = 0; oc < outC; ++oc)
        {
            Matrix2D<double> sum(in[0].rows(), in[0].cols());
            for (std::size_t ic = 0; ic < inC; ++ic)
            {
                auto c =
                    FFTCrossCorrelation2D_CUDA::compute(
                        in[ic],
                        kernels[oc * inC + ic],
                        PaddingMode::SAME
                    );

                for (std::size_t y = 0; y < sum.rows(); ++y)
                    for (std::size_t x = 0; x < sum.cols(); ++x)
                        sum(y, x) += c(y, x);
            }

            for (std::size_t y = 0; y < sum.rows(); ++y)
                for (std::size_t x = 0; x < sum.cols(); ++x)
                    sum(y, x) += bias[oc];

            out[oc] = std::move(sum);
        }
        return out;
    }
};

#pragma once
#include <fstream>

class InferenceStatsWriter
{
    std::ofstream f;
public:
    InferenceStatsWriter(const std::string& p)
        : f(p) { f << "id,gt,pred,time_ms\n"; }

    void write(int i, int g, int p, double t)
    {
        f << i << "," << g << "," << p << "," << t << "\n";
    }
};

#pragma once
#include <string>
#include <cstdlib>

class LabelExtractor
{
public:
    static int from(const std::string& s)
    {
        auto p = s.find("_label_");
        return std::atoi(s.c_str() + p + 7);
    }
};

#pragma once
#include <vector>

class LinearLayer
{
    std::size_t inF, outF;
    std::vector<double> w, b;

public:
    LinearLayer(
        std::size_t i, std::size_t o,
        const std::vector<double>& W,
        const std::vector<double>& B
    ) : inF(i), outF(o), w(W), b(B) {}

    std::vector<double> forward(
        const std::vector<double>& x
    ) const
    {
        std::vector<double> y(outF, 0.0);
        for (std::size_t o = 0; o < outF; ++o)
        {
            double s = b[o];
            for (std::size_t i = 0; i < inF; ++i)
                s += x[i] * w[o * inF + i];
            y[o] = s;
        }
        return y;
    }
};

#include "STL10CNN_Inference.hpp"
#include "NpyImageLoader.hpp"
#include "LabelExtractor.hpp"
#include "InferenceStatsWriter.hpp"
#include "WeightLoader.hpp"

#include <filesystem>
#include <chrono>
#include <iostream>
#include <algorithm>
#include <vector>
#include <fstream>

void writeInferenceSummary(
    const std::string& path,
    int samples,
    int correct,
    double totalTimeMs
)
{
    std::ofstream file(path);
    if (!file)
        throw std::runtime_error("Failed to open inference summary file");

    double accuracy = 100.0 * correct / samples;
    double avgTime = totalTimeMs / samples;

    file << "STL10 CNN Inference Statistics (only CUDA FFT Conv)\n";
    file << "-----------------------------\n";
    file << "Samples           : " << samples << "\n";
    file << "Accuracy (%)      : " << accuracy << "\n";
    file << "Total Time (ms)   : " << totalTimeMs << "\n";
    file << "Avg / Image (ms)  : " << avgTime << "\n";
}

int main()
{
    std::cout << "==============================\n";
    std::cout << "STL10 FFT Inference Started\n";
    std::cout << "==============================\n\n";
    std::cout << std::flush;

    /* =========================================================
       Load convolution weights (nn.Sequential indices: 0,3,6,9)
       ========================================================= */

    auto w1 = WeightLoader::load(
        "../../python/weights_bin/features_0_weight.bin",
        32 * 3 * 5 * 5
    );
    auto b1 = WeightLoader::load(
        "../../python/weights_bin/features_0_bias.bin",
        32
    );

    auto w2 = WeightLoader::load(
        "../../python/weights_bin/features_3_weight.bin",
        64 * 32 * 5 * 5
    );
    auto b2 = WeightLoader::load(
        "../../python/weights_bin/features_3_bias.bin",
        64
    );

    auto w3 = WeightLoader::load(
        "../../python/weights_bin/features_6_weight.bin",
        128 * 64 * 3 * 3
    );
    auto b3 = WeightLoader::load(
        "../../python/weights_bin/features_6_bias.bin",
        128
    );

    auto w4 = WeightLoader::load(
        "../../python/weights_bin/features_9_weight.bin",
        256 * 128 * 3 * 3
    );
    auto b4 = WeightLoader::load(
        "../../python/weights_bin/features_9_bias.bin",
        256
    );

    /* =========================================================
       Load classifier weights
       ========================================================= */

    auto wfc1 = WeightLoader::load(
        "../../python/weights_bin/classifier_0_weight.bin",
        512 * 256 * 6 * 6
    );
    auto bfc1 = WeightLoader::load(
        "../../python/weights_bin/classifier_0_bias.bin",
        512
    );

    auto wfc2 = WeightLoader::load(
        "../../python/weights_bin/classifier_2_weight.bin",
        10 * 512
    );
    auto bfc2 = WeightLoader::load(
        "../../python/weights_bin/classifier_2_bias.bin",
        10
    );

    std::cout << "Weights loaded successfully\n\n";
    std::cout << std::flush;

    /* =========================================================
       Build network
       ========================================================= */

    Conv2D_FFT c1(3,   32, 5, w1, b1);
    Conv2D_FFT c2(32,  64, 5, w2, b2);
    Conv2D_FFT c3(64, 128, 3, w3, b3);
    Conv2D_FFT c4(128,256, 3, w4, b4);

    LinearLayer f1(256 * 6 * 6, 512, wfc1, bfc1);
    LinearLayer f2(512, 10, wfc2, bfc2);

    STL10CNN_Inference model(
        std::move(c1),
        std::move(c2),
        std::move(c3),
        std::move(c4),
        std::move(f1),
        std::move(f2)
    );

    std::cout << "Model constructed\n\n";
    std::cout << std::flush;

    /* =========================================================
       Count test images
       ========================================================= */

    const std::string testDir = "../../python/test_images";

    int totalImages = 0;
    for (const auto& _ : std::filesystem::directory_iterator(testDir))
        totalImages++;

    std::cout << "Found " << totalImages << " test images\n\n";
    std::cout << std::flush;

    /* =========================================================
       Inference loop (WITH VISIBILITY)
       ========================================================= */

    InferenceStatsWriter csv("inference_stats.csv");

    int idx = 0;
    int correct = 0;
    double totalTimeMs = 0.0;

    for (const auto& entry :
         std::filesystem::directory_iterator(testDir))
    {
        const std::string path = entry.path().string();

        std::cout << "[IMAGE " << (idx + 1)
                  << " / " << totalImages << "] loading\n";
        std::cout << std::flush;

        auto input = NpyImageLoader::load(path);
        int gt = LabelExtractor::from(path);

        std::cout << "  running inference...\n";
        std::cout << std::flush;

        auto t0 = std::chrono::high_resolution_clock::now();
        auto output = model.forward(input);
        auto t1 = std::chrono::high_resolution_clock::now();

        double timeMs =
            std::chrono::duration<double, std::milli>(t1 - t0).count();

        int pred =
            std::max_element(output.begin(), output.end()) - output.begin();

        csv.write(idx, gt, pred, timeMs);

        if (pred == gt)
            correct++;

        totalTimeMs += timeMs;

        std::cout << "  done in " << timeMs << " ms"
                  << " | pred=" << pred
                  << " | gt=" << gt << "\n\n";
        std::cout << std::flush;

        idx++;
    }

    /* =========================================================
       Summary
       ========================================================= */

    std::cout << "==============================\n";
    std::cout << "Inference completed\n";
    std::cout << "Accuracy: "
              << (100.0 * correct / totalImages) << " %\n";
    std::cout << "Average inference time: "
              << (totalTimeMs / totalImages) << " ms\n";
    std::cout << "CSV written to inference_stats.csv\n";
    std::cout << "==============================\n";

    writeInferenceSummary(
        "inference_summary.txt",
        totalImages,
        correct,
        totalTimeMs
    );


    return 0;
}

#ifndef MAXPOOL2D_HPP
#define MAXPOOL2D_HPP

#include "../Matrix2D.hpp"
#include <algorithm>

class MaxPool2D
{
public:
    static Matrix2D<double> apply(const Matrix2D<double>& input)
    {
        std::size_t outH = input.rows() / 2;
        std::size_t outW = input.cols() / 2;

        Matrix2D<double> output(outH, outW);

        for (std::size_t y = 0; y < outH; ++y)
            for (std::size_t x = 0; x < outW; ++x)
            {
                double m = input(2*y, 2*x);
                m = std::max(m, input(2*y, 2*x + 1));
                m = std::max(m, input(2*y + 1, 2*x));
                m = std::max(m, input(2*y + 1, 2*x + 1));
                output(y, x) = m;
            }

        return output;
    }
};

#endif

#ifndef NORMALIZATION_HPP
#define NORMALIZATION_HPP

#include "../Matrix2D.hpp"
#include <vector>

class Normalization
{
public:
    static void apply(
        std::vector<Matrix2D<double>>& channels
    )
    {
        static const double mean[3] = {
            0.4467, 0.4398, 0.4066
        };
        static const double std[3] = {
            0.2241, 0.2215, 0.2239
        };

        for (std::size_t c = 0; c < 3; ++c)
            for (std::size_t y = 0; y < channels[c].rows(); ++y)
                for (std::size_t x = 0; x < channels[c].cols(); ++x)
                    channels[c](y, x) =
                        (channels[c](y, x) - mean[c]) / std[c];
    }
};

#endif

#pragma once
#include "../Matrix2D.hpp"
#include "../cnpy/cnpy.h"
#include <vector>
#include <string>

class NpyImageLoader
{
public:
    static std::vector<Matrix2D<double>> load(
        const std::string& path
    )
    {
        auto arr = cnpy::npy_load(path);
        const float* d = arr.data<float>();

        std::size_t C = arr.shape[0];
        std::size_t H = arr.shape[1];
        std::size_t W = arr.shape[2];

        std::vector<Matrix2D<double>> out;
        std::size_t off = 0;

        for (std::size_t c = 0; c < C; ++c)
        {
            Matrix2D<double> m(H, W);
            for (std::size_t y = 0; y < H; ++y)
                for (std::size_t x = 0; x < W; ++x)
                    m(y, x) = d[off++];
            out.push_back(std::move(m));
        }
        return out;
    }
};

#pragma once
#include "Conv2D_FFT.hpp"
#include "LinearLayer.hpp"
#include "MaxPool2D.hpp"
#include "Normalization.hpp"
#include <algorithm>

class STL10CNN_Inference
{
    Conv2D_FFT c1, c2, c3, c4;
    LinearLayer f1, f2;

    static void relu(Matrix2D<double>& m)
    {
        for (std::size_t y = 0; y < m.rows(); ++y)
            for (std::size_t x = 0; x < m.cols(); ++x)
                m(y, x) = std::max(0.0, m(y, x));
    }

public:
    STL10CNN_Inference(
        Conv2D_FFT&& a, Conv2D_FFT&& b,
        Conv2D_FFT&& c, Conv2D_FFT&& d,
        LinearLayer&& e, LinearLayer&& f
    ) : c1(a), c2(b), c3(c), c4(d), f1(e), f2(f) {}

    std::vector<double> forward(
        std::vector<Matrix2D<double>> x
    )
    {
        /* -------- INPUT NORMALIZATION -------- */
        Normalization::apply(x);

        /* -------- CONV BLOCK 1 -------- */
        x = c1.forward(x);
        for (auto& m : x)
        {
            for (std::size_t y = 0; y < m.rows(); ++y)
                for (std::size_t z = 0; z < m.cols(); ++z)
                    m(y, z) = std::max(0.0, m(y, z));
            m = MaxPool2D::apply(m);
        }

        /* -------- CONV BLOCK 2 -------- */
        x = c2.forward(x);
        for (auto& m : x)
        {
            for (std::size_t y = 0; y < m.rows(); ++y)
                for (std::size_t z = 0; z < m.cols(); ++z)
                    m(y, z) = std::max(0.0, m(y, z));
            m = MaxPool2D::apply(m);
        }

        /* -------- CONV BLOCK 3 -------- */
        x = c3.forward(x);
        for (auto& m : x)
        {
            for (std::size_t y = 0; y < m.rows(); ++y)
                for (std::size_t z = 0; z < m.cols(); ++z)
                    m(y, z) = std::max(0.0, m(y, z));
            m = MaxPool2D::apply(m);
        }

        /* -------- CONV BLOCK 4 -------- */
        x = c4.forward(x);
        for (auto& m : x)
        {
            for (std::size_t y = 0; y < m.rows(); ++y)
                for (std::size_t z = 0; z < m.cols(); ++z)
                    m(y, z) = std::max(0.0, m(y, z));
            m = MaxPool2D::apply(m);
        }

        /* -------- FLATTEN -------- */
        std::vector<double> flat;
        flat.reserve(256 * 6 * 6);

        for (const auto& c : x)
            for (std::size_t y = 0; y < c.rows(); ++y)
                for (std::size_t z = 0; z < c.cols(); ++z)
                    flat.push_back(c(y, z));

        /* -------- FC -------- */
        auto h = f1.forward(flat);
        for (auto& v : h)
            v = std::max(0.0, v);

        return f2.forward(h);
    }
};

#pragma once
#include <vector>
#include <string>
#include <fstream>
#include <stdexcept>

class WeightLoader
{
public:
    static std::vector<double> load(
        const std::string& path,
        std::size_t expected
    )
    {
        std::vector<double> data(expected);
        std::ifstream f(path, std::ios::binary);
        if (!f) throw std::runtime_error("Weight open failed");

        f.read(reinterpret_cast<char*>(data.data()),
               expected * sizeof(double));

        if (!f) throw std::runtime_error("Weight read failed");
        return data;
    }
};
